{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Facial Emotion Detection using CNN and VGG16\n", "This notebook contains two deep learning models:\n", "1. A Convolutional Neural Network (CNN) model (your existing model).\n", "2. A VGG16-based model using transfer learning.\n", "\n", "Both models will be trained on the same dataset and evaluated for performance."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import tensorflow as tf\n", "from tensorflow.keras import layers, models\n", "from tensorflow.keras.applications import VGG16\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "\n", "print(\"TensorFlow version:\", tf.__version__)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Preparation\n", "Update the `train_dir` and `val_dir` variables to point to your training and validation data directories. The images will be resized to `224x224` pixels (the required input size for VGG16)."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Parameters and Data Setup\n", "train_dir = 'data/train'  # Update to your training data path\n", "val_dir = 'data/val'      # Update to your validation data path\n", "\n", "img_height, img_width = 224, 224\n", "batch_size = 32\n", "num_classes = 7\n", "\n", "# Data augmentation and preprocessing\n", "train_datagen = ImageDataGenerator(\n", "    rescale=1./255,\n", "    horizontal_flip=True,\n", "    rotation_range=10,\n", "    zoom_range=0.1\n", ")\n", "\n", "val_datagen = ImageDataGenerator(rescale=1./255)\n", "\n", "train_generator = train_datagen.flow_from_directory(\n", "    train_dir,\n", "    target_size=(img_height, img_width),\n", "    batch_size=batch_size,\n", "    class_mode='categorical'\n", ")\n", "\n", "validation_generator = val_datagen.flow_from_directory(\n", "    val_dir,\n", "    target_size=(img_height, img_width),\n", "    batch_size=batch_size,\n", "    class_mode='categorical'\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## VGG16-Based Model Definition"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["input_shape = (img_height, img_width, 3)\n", "\n", "# Load VGG16 without top layers\n", "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n", "base_model.trainable = False\n", "\n", "# Add custom layers\n", "vgg16_model = models.Sequential([\n", "    base_model,\n", "    layers.Flatten(),\n", "    layers.Dense(128, activation='relu'),\n", "    layers.Dropout(0.5),\n", "    layers.Dense(num_classes, activation='softmax')\n", "])\n", "\n", "# Compile the model\n", "vgg16_model.compile(optimizer='adam',\n", "                     loss='categorical_crossentropy',\n", "                     metrics=['accuracy'])\n", "\n", "vgg16_model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the VGG16 Model"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["epochs = 10\n", "history_vgg16 = vgg16_model.fit(\n", "    train_generator,\n", "    epochs=epochs,\n", "    validation_data=validation_generator\n", ")\n", "print(\"Training complete.\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save the VGG16 Model"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["vgg16_model.save('vgg16_emotion_model.h5')\n", "print(\"Model saved as vgg16_emotion_model.h5\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}